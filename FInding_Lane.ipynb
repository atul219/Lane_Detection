{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_fn():\n",
    "    obj_pts = np.zeros((6*9,3), np.float32)\n",
    "    obj_pts[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "        # store all corners and object point in these two lists\n",
    "    corner_pts = []\n",
    "    object_pts = []\n",
    "\n",
    "    # read the directory of chessboard images\n",
    "    images = glob.glob('./camera_calibration/*.jpg')\n",
    "\n",
    "    for index, file_name in enumerate(images):\n",
    "        img = cv2.imread(file_name)\n",
    "        gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # find corners in the gray scale img\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6) , None)\n",
    "\n",
    "        if ret == True:\n",
    "            corner_pts.append(corners)\n",
    "            object_pts.append(obj_pts)\n",
    "\n",
    "            img = cv2.drawChessboardCorners(img , (7,6) , corners,ret)\n",
    "          #  cv2.imshow('img' , img)\n",
    "           # cv2.waitKey(500)\n",
    "\n",
    "    #cv2.destroyAllWindows()\n",
    "    gray_zise = (img.shape[1] , img.shape[0])        \n",
    "\n",
    "    #This method returns the camera matrix, distortion coefficients, rotation and translation vectors etc.\n",
    "    ret , mtx , dist , rvecs , tvecs = cv2.calibrateCamera(object_pts , corner_pts , gray_zise,None,None)\n",
    "\n",
    "    # undistort the image\n",
    "\n",
    "    undistort_img = cv2.undistort(img,mtx,dist ,None ,mtx)\n",
    "\n",
    "    dist_pickle = {}\n",
    "    dist_pickle['mtx'] = mtx\n",
    "    dist_pickle['dist'] = dist\n",
    "    pickle.dump( dist_pickle, open('camera_calibration/calibration_picke.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_images(img , calibration_dir = './camera_calibration/calibration_picke.p'):\n",
    "    \n",
    "    with open(calibration_dir , mode='rb') as f:\n",
    "        file = pickle.load(f)\n",
    "        mtx = file['mtx']\n",
    "        dist = file['dist']\n",
    "        \n",
    "        undistort_img = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "        \n",
    "        return undistort_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_pipeline_hls(img ,s_gradient_thresh = (15,255), s_channel_thresh = (100,255)):\n",
    "    img = undistort_images(img)\n",
    "    \n",
    "    # copy of image\n",
    "    img_copy = np.copy(img)\n",
    "    \n",
    "    # calculate hls color scheme\n",
    "    hls = cv2.cvtColor(img_copy , cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    h_hls = hls[:,:,0]\n",
    "    l_hls = hls[:,:,1]\n",
    "    s_hls = hls[:,:,2]\n",
    "    \n",
    "    # find edges\n",
    "    x_sobel = cv2.Sobel(l_hls , cv2.CV_64F , 1,1)\n",
    "    \n",
    "    abs_sobel = np.absolute(x_sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    gradient_binary = np.zeros_like(scaled_sobel)\n",
    "    gradient_binary[(scaled_sobel >= s_gradient_thresh[0]) & (scaled_sobel <= s_gradient_thresh[1])]   \n",
    "    \n",
    "    # Threshold color channel\n",
    "    channel_binary = np.zeros_like(s_hls)\n",
    "    channel_binary[(s_hls >= s_channel_thresh[0]) & (s_hls <= s_channel_thresh[1])] = 1\n",
    "    \n",
    "    combined_binary = np.zeros_like(gradient_binary)\n",
    "    combined_binary[(channel_binary == 1) | (gradient_binary == 1)] = 1\n",
    "        \n",
    "    return combined_binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_pipeline_hsv(img ,s_gradient_thresh = (15,255), s_channel_thresh = (100,255)):\n",
    "    img = undistort_images(img)\n",
    "    \n",
    "    # copy of image\n",
    "    img_copy = np.copy(img)\n",
    "    \n",
    "     # calculate hsv color scheme\n",
    "    hsv = cv2.cvtColor(img_copy , cv2.COLOR_RGB2HSV)\n",
    "    h_hsv = hsv[:,:,0]\n",
    "    s_hsv = hsv[:,:,1]\n",
    "    v_hsv = hsv[:,:,2]\n",
    "    \n",
    "    \n",
    "    x_sobel = cv2.Sobel(v_hsv , cv2.CV_64F , 1, 1)\n",
    "    \n",
    "    abs_sobel = np.absolute(x_sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # Threshold Binary\n",
    "    gradient_binary = np.zeros_like(scaled_sobel)\n",
    "    gradient_binary[(scaled_sobel >= s_gradient_thresh[0]) & (scaled_sobel <= s_gradient_thresh[1])] \n",
    "    \n",
    "    # Threshold color Channel\n",
    "    channel_binary = np.zeros_like(s_hsv)\n",
    "    channel_binary[(s_hsv >= s_channel_thresh[0]) & (s_hsv <= s_channel_thresh[1])] = 1\n",
    "    \n",
    "    combined_binary = np.zeros_like(gradient_binary)\n",
    "    combined_binary[(channel_binary == 1) | (gradient_binary == 1)] = 1\n",
    "    \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-832cee42e6f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize undistortion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0max1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Original Image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundistort_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAJDCAYAAACPEUSwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGqFJREFUeJzt3W+o5Xd94PH3R9O0rLXt0kyh5E/jsnFtkAXdwXUpbC26S/RB8sQtCUhrEQPdTRe2UnDpYkv6aC2LUMiuzVKxFWpMfdAOJSULrcVSGsmIWzGRwGzqmiEFU2t9Ippm97sP7l0ZrzPOcXLvmZM5rxccOH++3PslX2bmk/f9nXNnrRUAAAAA++1lV3sDAAAAAFx9IhEAAAAAIhEAAAAAIhEAAAAAiUQAAAAAJBIBAAAA0AaRaGY+NDNfmpnPXeL1mZnfmJlzM/PZmXn98W8TAGC/mMEAgG3b5EqiD1d3fIfX31rddni7t/pvL35bAAB778OZwQCALbpsJFprfbL62++w5K7qd9aBx6ofmpkfPa4NAgDsIzMYALBtx/GZRDdWz1zw+PzhcwAAnBwzGABwrK47hq8xF3luXXThzL0dXA7dK17xin/2mte85hi+PQCwiz796U//zVrr1NXexzXMDAYAfJsXM4MdRyQ6X918weObqmcvtnCt9WD1YNXp06fX2bNnj+HbAwC7aGb+99XewzXODAYAfJsXM4Mdx9vNzlQ/c/gbNt5YfXWt9dfH8HUBALg0MxgAcKwueyXRzHy0elN1w8ycr36l+p6qtdYHq0eqt1Xnqq9VP3dSmwUA2BdmMABg2y4bidZa91zm9VX9u2PbEQAAZjAAYOuO4+1mAAAAALzEiUQAAAAAiEQAAAAAiEQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAtGEkmpk7ZuapmTk3M++9yOu3zMwnZuYzM/PZmXnb8W8VAGC/mMEAgG26bCSamZdXD1RvrW6v7pmZ248s+0/Vw2ut11V3V//1uDcKALBPzGAAwLZtciXRG6pza62n11rPVw9Vdx1Zs6ofOLz/g9Wzx7dFAIC9ZAYDALbqug3W3Fg9c8Hj89U/P7LmV6v/MTO/UL2iesux7A4AYH+ZwQCArdrkSqK5yHPryON7qg+vtW6q3lZ9ZGa+7WvPzL0zc3Zmzj733HPf/W4BAPaHGQwA2KpNItH56uYLHt/Ut1/K/K7q4aq11l9U31fdcPQLrbUeXGudXmudPnXq1JXtGABgP5jBAICt2iQSPV7dNjOvmpnrO/hQxDNH1nyxenPVzPx4BwOKH1MBAFw5MxgAsFWXjURrrReq+6pHq8938Bs0npiZ+2fmzsNl76nePTN/WX20euda6+jl0AAAbMgMBgBs2yYfXN1a65HqkSPPve+C+09WP3G8WwMA2G9mMABgmzZ5uxkAAAAA1ziRCAAAAACRCAAAAACRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIA2jEQzc8fMPDUz52bmvZdY89Mz8+TMPDEzv3u82wQA2D9mMABgm6673IKZeXn1QPWvqvPV4zNzZq315AVrbqv+Y/UTa62vzMyPnNSGAQD2gRkMANi2Ta4kekN1bq319Frr+eqh6q4ja95dPbDW+krVWutLx7tNAIC9YwYDALZqk0h0Y/XMBY/PHz53oVdXr56ZP5+Zx2bmjuPaIADAnjKDAQBbddm3m1VzkefWRb7ObdWbqpuqP5uZ1661/u5bvtDMvdW9Vbfccst3vVkAgD1iBgMAtmqTK4nOVzdf8Pim6tmLrPmDtdbfr7X+qnqqg4HlW6y1HlxrnV5rnT516tSV7hkAYB+YwQCArdokEj1e3TYzr5qZ66u7qzNH1vx+9VNVM3NDB5c+P32cGwUA2DNmMABgqy4bidZaL1T3VY9Wn68eXms9MTP3z8ydh8serb48M09Wn6h+aa315ZPaNADAtc4MBgBs26x19K3t23H69Ol19uzZq/K9AYCTNzOfXmudvtr74FuZwQDg2vZiZrBN3m4GAAAAwDVOJAIAAABAJAIAAABAJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABow0g0M3fMzFMzc25m3vsd1r19ZtbMnD6+LQIA7CczGACwTZeNRDPz8uqB6q3V7dU9M3P7Rda9svr31aeOe5MAAPvGDAYAbNsmVxK9oTq31np6rfV89VB110XW/Vr1/urrx7g/AIB9ZQYDALZqk0h0Y/XMBY/PHz73TTPzuurmtdYfHuPeAAD2mRkMANiqTSLRXOS59c0XZ15WfaB6z2W/0My9M3N2Zs4+99xzm+8SAGD/mMEAgK3aJBKdr26+4PFN1bMXPH5l9drqT2fmC9UbqzMX++DEtdaDa63Ta63Tp06duvJdAwBc+8xgAMBWbRKJHq9um5lXzcz11d3Vmf//4lrrq2utG9Zat661bq0eq+5ca509kR0DAOwHMxgAsFWXjURrrReq+6pHq89XD6+1npiZ+2fmzpPeIADAPjKDAQDbdt0mi9Zaj1SPHHnufZdY+6YXvy0AAMxgAMA2bfJ2MwAAAACucSIRAAAAACIRAAAAACIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAIlEAAAAACQSAQAAAJBIBAAAAEAiEQAAAACJRAAAAAAkEgEAAACQSAQAAABAIhEAAAAAiUQAAAAAJBIBAAAAkEgEAAAAQCIRAAAAAG0YiWbmjpl5ambOzcx7L/L6L87MkzPz2Zn545n5sePfKgDAfjGDAQDbdNlINDMvrx6o3lrdXt0zM7cfWfaZ6vRa659WH6/ef9wbBQDYJ2YwAGDbNrmS6A3VubXW02ut56uHqrsuXLDW+sRa62uHDx+rbjrebQIA7B0zGACwVZtEohurZy54fP7wuUt5V/VHL2ZTAACYwQCA7bpugzVzkefWRRfOvKM6Xf3kJV6/t7q36pZbbtlwiwAAe8kMBgBs1SZXEp2vbr7g8U3Vs0cXzcxbql+u7lxrfeNiX2it9eBa6/Ra6/SpU6euZL8AAPvCDAYAbNUmkejx6raZedXMXF/dXZ25cMHMvK76zQ6Gky8d/zYBAPaOGQwA2KrLRqK11gvVfdWj1eerh9daT8zM/TNz5+GyX6++v/q9mfmfM3PmEl8OAIANmMEAgG3b5DOJWms9Uj1y5Ln3XXD/Lce8LwCAvWcGAwC2aZO3mwEAAABwjROJAAAAABCJAAAAABCJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAEgkAgAAACCRCAAAAIBEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAEokAAAAASCQCAAAAIJEIAAAAgEQiAAAAABKJAAAAAGjDSDQzd8zMUzNzbmbee5HXv3dmPnb4+qdm5tbj3igAwL4xgwEA23TZSDQzL68eqN5a3V7dMzO3H1n2ruora61/XH2g+s/HvVEAgH1iBgMAtm2TK4neUJ1baz291nq+eqi668iau6rfPrz/8erNMzPHt00AgL1jBgMAtmqTSHRj9cwFj88fPnfRNWutF6qvVj98HBsEANhTZjAAYKuu22DNxX4ata5gTTNzb3Xv4cNvzMznNvj+bNcN1d9c7U3wLZzJ7nEmu8m57J5/crU38BJnBtsf/v7aTc5l9ziT3eRcds8Vz2CbRKLz1c0XPL6pevYSa87PzHXVD1Z/e/QLrbUerB6smpmza63TV7JpTo5z2T3OZPc4k93kXHbPzJy92nt4iTOD7Qlnspucy+5xJrvJueyeFzODbfJ2s8er22bmVTNzfXV3debImjPVzx7ef3v1J2utb/spFgAAGzODAQBbddkridZaL8zMfdWj1curD621npiZ+6uza60z1W9VH5mZcx389Oruk9w0AMC1zgwGAGzbJm83a631SPXIkefed8H9r1f/5rv83g9+l+vZDueye5zJ7nEmu8m57B5n8iKZwfaGM9lNzmX3OJPd5Fx2zxWfybgiGQAAAIBNPpMIAAAAgGvciUeimbljZp6amXMz896LvP69M/Oxw9c/NTO3nvSe9t0GZ/KLM/PkzHx2Zv54Zn7sauxz31zuXC5Y9/aZWTPjNwicsE3OZGZ++vDPyxMz87vb3uM+2uDvsFtm5hMz85nDv8fedjX2uU9m5kMz86VL/Vr1OfAbh2f22Zl5/bb3uI/MYLvHDLZ7zF+7yQy2e8xfu+fE5q+11ondOviQxf9V/aPq+uovq9uPrPm31QcP799dfewk97Tvtw3P5Keqf3B4/+edyW6cy+G6V1afrB6rTl/tfV/Ltw3/rNxWfab6h4ePf+Rq7/tav214Lg9WP394//bqC1d739f6rfqX1eurz13i9bdVf1RN9cbqU1d7z9f6zQy2ezcz2O7dzF+7eTOD7d7N/LWbt5Oav076SqI3VOfWWk+vtZ6vHqruOrLmruq3D+9/vHrzzMwJ72ufXfZM1lqfWGt97fDhY9VNW97jPtrkz0rVr1Xvr76+zc3tqU3O5N3VA2utr1Sttb605T3uo03OZVU/cHj/B6tnt7i/vbTW+mQHv1nrUu6qfmcdeKz6oZn50e3sbm+ZwXaPGWz3mL92kxls95i/dtBJzV8nHYlurJ654PH5w+cuumat9UL11eqHT3hf+2yTM7nQuzqoj5ysy57LzLyuunmt9Yfb3Nge2+TPyqurV8/Mn8/MYzNzx9Z2t782OZdfrd4xM+c7+K1Qv7CdrfEdfLf/9vDimcF2jxls95i/dpMZbPeYv16armj+uu7EtnPgYj+NOvrr1DZZw/HZ+L/3zLyjOl395InuiLrMuczMy6oPVO/c1obY6M/KdR1c7vymDn7a+2cz89q11t+d8N722Sbnck/14bXWf5mZf1F95PBc/u/Jb49L8G/99pnBdo8ZbPeYv3aTGWz3mL9emq7o3/mTvpLofHXzBY9v6tsvO/vmmpm5roNL077TJVO8OJucSTPzluqXqzvXWt/Y0t722eXO5ZXVa6s/nZkvdPCe0jM+PPFEbfr31x+stf5+rfVX1VMdDCycnE3O5V3Vw1Vrrb+ovq+6YSu741I2+reHY2UG2z1msN1j/tpNZrDdY/56abqi+eukI9Hj1W0z86qZub6DD0U8c2TNmepnD++/vfqTdfgpS5yIy57J4WW1v9nBcOL9vdvxHc9lrfXVtdYNa61b11q3dvA5BXeutc5ene3uhU3+/vr9Dj5ktJm5oYNLn5/e6i73zybn8sXqzVUz8+MdDCnPbXWXHHWm+pnD37Lxxuqra62/vtqbusaZwXaPGWz3mL92kxls95i/XpquaP460bebrbVemJn7qkc7+ET0D621npiZ+6uza60z1W91cCnauQ5+enX3Se5p3214Jr9efX/1e4efX/nFtdadV23Te2DDc2GLNjyTR6t/PTNPVv+n+qW11pev3q6vfRuey3uq/z4z/6GDS2rf6X98T9bMfLSDS/5vOPwsgl+pvqdqrfXBDj6b4G3Vuepr1c9dnZ3uDzPY7jGD7R7z124yg+0e89duOqn5a5wbAAAAACf9djMAAAAAXgJEIgAAAABEIgAAAABEIgAAAAASiQAAAABIJAIAAAAgkQgAAACARCIAAAAAqv8HLnWGK8mGN+IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(undistort_img)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get birds eye view\n",
    "\n",
    "# create a transoform matrix\n",
    "def perspective_warp(img, \n",
    "                     dst_size=(1280,720),\n",
    "                     src=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)]),\n",
    "                     dst=np.float32([(0,0), (1, 0), (0,1), (1,1)])):\n",
    "    \n",
    "    img_size = np.float32([(img.shape[1],img.shape[0])]) \n",
    "    src = src *img_size\n",
    "    \n",
    "    dst = dst*np.float32(dst_size)\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src , dst)\n",
    "    \n",
    "    warped = cv2.warpPerspective(img ,M, dst_size)\n",
    "    \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_perspective_warp(img, \n",
    "                     dst_size=(1280,720),\n",
    "                     src=np.float32([(0,0), (1, 0), (0,1), (1,1)]),\n",
    "                     dst=np.float32([(0.43,0.65),(0.58,0.65),(0.1,1),(1,1)])):\n",
    "    \n",
    "    img_size = np.float32([(img.shape[1],img.shape[0])]) \n",
    "    src = src *img_size\n",
    "    \n",
    "    dst = dst*np.float32(dst_size)\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src , dst)\n",
    "    \n",
    "    warped = cv2.warpPerspective(img ,M, dst_size)\n",
    "    \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(img):\n",
    "    hist = np.sum(img[img.shape[0]//2:,:] , axis = 0)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_a, left_b, left_c = [],[],[]\n",
    "right_a, right_b, right_c = [],[],[]\n",
    "\n",
    "def sliding_window(img, nwindows=9, margin=150, minpix = 1, draw_windows=True):\n",
    "    global left_a, left_b, left_c,right_a, right_b, right_c \n",
    "    left_fit_= np.empty(3)\n",
    "    right_fit_ = np.empty(3)\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "\n",
    "    histogram = get_hist(img)\n",
    "    # find peaks of left and right halves\n",
    "    midpoint = int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        if draw_windows == True:\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "            (100,255,255), 3) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "            (100,255,255), 3) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    left_a.append(left_fit[0])\n",
    "    left_b.append(left_fit[1])\n",
    "    left_c.append(left_fit[2])\n",
    "    \n",
    "    right_a.append(right_fit[0])\n",
    "    right_b.append(right_fit[1])\n",
    "    right_c.append(right_fit[2])\n",
    "    \n",
    "    left_fit_[0] = np.mean(left_a[-10:])\n",
    "    left_fit_[1] = np.mean(left_b[-10:])\n",
    "    left_fit_[2] = np.mean(left_c[-10:])\n",
    "    \n",
    "    right_fit_[0] = np.mean(right_a[-10:])\n",
    "    right_fit_[1] = np.mean(right_b[-10:])\n",
    "    right_fit_[2] = np.mean(right_c[-10:])\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx = left_fit_[0]*ploty**2 + left_fit_[1]*ploty + left_fit_[2]\n",
    "    right_fitx = right_fit_[0]*ploty**2 + right_fit_[1]*ploty + right_fit_[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 100]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 100, 255]\n",
    "    \n",
    "    return out_img, (left_fitx, right_fitx), (left_fit_, right_fit_), ploty\n",
    "\n",
    "def get_curve(img, leftx, rightx):\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    y_eval = np.max(ploty)\n",
    "    ym_per_pix = 30.5/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/720 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    car_pos = img.shape[1]/2\n",
    "    l_fit_x_int = left_fit_cr[0]*img.shape[0]**2 + left_fit_cr[1]*img.shape[0] + left_fit_cr[2]\n",
    "    r_fit_x_int = right_fit_cr[0]*img.shape[0]**2 + right_fit_cr[1]*img.shape[0] + right_fit_cr[2]\n",
    "    lane_center_position = (r_fit_x_int + l_fit_x_int) /2\n",
    "    center = (car_pos - lane_center_position) * xm_per_pix / 10\n",
    "    # Now our radius of curvature is in meters\n",
    "    return (left_curverad, right_curverad, center)\n",
    "\n",
    "def draw_lanes(img, left_fit, right_fit):\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    color_img = np.zeros_like(img)\n",
    "    \n",
    "    left = np.array([np.transpose(np.vstack([left_fit, ploty]))])\n",
    "    right = np.array([np.flipud(np.transpose(np.vstack([right_fit, ploty])))])\n",
    "    points = np.hstack((left, right))\n",
    "    \n",
    "    cv2.fillPoly(color_img, np.int_(points), (0,200,255))\n",
    "    inv_perspective = inv_perspective_warp(color_img)\n",
    "    inv_perspective = cv2.addWeighted(img, 1, inv_perspective, 0.7, 0)\n",
    "    return inv_perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Warped Image')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('./test_images/test3.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "dst = complete_pipeline_hls(img)\n",
    "dst = perspective_warp(dst, dst_size=(1280,720))\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst, cmap='gray')\n",
    "ax2.set_title('Warped Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 720)\n",
      "(3127.943512037567, 1024.8875477153783, 0.254459328415389)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7ddfffba8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%matplotlib gtk\n",
    "out_img, curves, lanes, ploty = sliding_window(dst)\n",
    "#plt.imshow(out_img)\n",
    "#plt.plot(curves[0], ploty, color='yellow', linewidth=1)\n",
    "#plt.plot(curves[1], ploty, color='yellow', linewidth=1)\n",
    "print(np.asarray(curves).shape)\n",
    "curverad=get_curve(img, curves[0],curves[1])\n",
    "print(curverad)\n",
    "img_ = draw_lanes(img, curves[0], curves[1])\n",
    "plt.imshow(img_, cmap='hsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4 , ax5) = plt.subplots(1, 5, figsize=(100, 20))\n",
    "#f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original', fontsize=100)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Filter+Perspective Tform', fontsize=100)\n",
    "ax3.imshow(out_img)\n",
    "ax3.plot(curves[0], ploty, color='yellow', linewidth=30)\n",
    "ax3.plot(curves[1], ploty, color='yellow', linewidth=30)\n",
    "ax3.set_title('Sliding window+Curve Fit', fontsize=100)\n",
    "ax4.imshow(img_)\n",
    "\n",
    "ax4.set_title('Overlay Lanes', fontsize=100)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vid_pipeline(img):\n",
    "    global running_avg\n",
    "    global index\n",
    "    img_ = pipeline(img)\n",
    "    img_ = perspective_warp(img_)\n",
    "    out_img, curves, lanes, ploty = sliding_window(img_, draw_windows=False)\n",
    "    curverad =get_curve(img, curves[0], curves[1])\n",
    "    lane_curve = np.mean([curverad[0], curverad[1]])\n",
    "    img = draw_lanes(img, curves[0], curves[1])\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontColor = (0, 0, 0)\n",
    "    fontSize=0.5\n",
    "    cv2.putText(img, 'Lane Curvature: {:.0f} m'.format(lane_curve), (570, 620), font, fontSize, fontColor, 2)\n",
    "    cv2.putText(img, 'Vehicle offset: {:.4f} m'.format(curverad[2]), (570, 650), font, fontSize, fontColor, 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_curves, left_curves = [],[]\n",
    "#from moviepy.editor import VideoFileClip\n",
    "\n",
    "myclip = cv2.Vid\n",
    "#myclip = VideoFileClip('project_video.mp4')#.subclip(40,43)\n",
    "output_vid = 'output.mp4'\n",
    "clip = myclip.fl_image(vid_pipeline)\n",
    "clip.write_videofile(output_vid, audio=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
